# -*- coding: utf-8 -*-
"""Chatbot integration aiogram.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O3EdzjI9J33P0sjIJ8DXP2FWOv0Gmm_f
"""

import logging
import pandas as pd
import sys

from google.colab import drive
drive.mount('/content/drive')

from google.colab import userdata
import os

!pip install aiogram
#pip install --force-reinstall -v "aiogram==2.23.1"

from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
from aiogram.types import Message
from aiogram import F

TELEGRAM_BOT_TOKEN = userdata.get('TELEGRAM_BOT_TOKEN')

logging.basicConfig(level=logging.DEBUG, stream=sys.stdout)

from aiogram.fsm.storage.memory import MemoryStorage
storage = MemoryStorage()

bot = Bot(token=TELEGRAM_BOT_TOKEN)
dp = Dispatcher()

conversations = {}
user_states = {}
active_users = set()

from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

model_name = "polinasch/gpt2-small-arabic-finetuned-masry-final"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
model.to(device)

def tokenize(input_texts):
    return tokenizer(input_texts, return_tensors='pt', padding=True, truncation=True)

df = pd.read_csv('/content/drive/MyDrive/Arabic subtitles.xlsx - renewed.csv')

df = df.rename(columns={df.columns[0]: 'text'})

df = df[~df['text'].str.contains(r'\[[^\]]+\]')]

import re

def clean_text(text):
    cleaned_text = re.sub(r'[^\u0600-\u06FF\s]', '', text)
    return cleaned_text

df['cleaned_text'] = df['text'].apply(clean_text)

cleaned_df = df[df['cleaned_text'].str.strip() != '']

print(cleaned_df)

texts = cleaned_df['text'].tolist()

async def generate_response_with_model_and_faiss(message_list, model, tokenizer, device):
    """
    Generate a response to a message using the model and tokenizer.
    """
    try:
        print(f"Model device: {next(model.parameters()).device}")

        text_inputs = [message['content'] for message in message_list]
        print(f"Text inputs: {text_inputs}")

        inputs = tokenizer(text_inputs, return_tensors="pt", padding=True, truncation=True, max_length=512)
        print(f"Inputs: {inputs}")

        input_ids = inputs['input_ids'].to(device)
        attention_mask = inputs['attention_mask'].to(device)

        sample_outputs = model.generate(
            input_ids,
            attention_mask=attention_mask,
            do_sample=True,
            temperature=0.7,
            top_k=50,
            max_length=200,
            top_p=0.8,
            num_return_sequences=3,
            pad_token_id=tokenizer.pad_token_id,
            eos_token_id=tokenizer.eos_token_id,
        )

        print(f"Sample outputs: {sample_outputs}")

        responses = []
        for sample_output in sample_outputs:
            response_text = tokenizer.decode(sample_output, skip_special_tokens=True)
            truncated_response = response_text[:4000] if len(response_text) > 4000 else response_text
            responses.append(truncated_response.strip())

        print(f"Generated responses: {responses}")

        return responses

    except Exception as e:
        print(f"An error occurred during response generation: {e}")
        return ["Sorry, something went wrong."]

async def conversation_tracking(text_message, user_id):
    """
    Track and manage conversations for a user.
    """
    user_conversations = conversations.get(user_id, {'conversations': [], 'responses': []})

    user_messages = user_conversations['conversations'] + [text_message]
    user_responses = user_conversations['responses']

    conversation_history = []
    for i in range(len(user_messages)):
        conversation_history.append({
            "role": "user", "content": user_messages[i]
        })
        if i < len(user_responses):
            conversation_history.append({
                "role": "assistant", "content": user_responses[i]
            })

    conversation_history.append({
        "role": "user", "content": text_message
    })

    print("Message list for tokenization:", conversation_history)

    responses = generate_response_with_model_and_faiss(conversation_history, model, tokenizer, device)

    print("Generated responses:", responses)

    if responses:
        user_responses.append(responses[0])

    conversations[user_id] = {'conversations': user_messages, 'responses': user_responses}

    return responses[0] if responses else "Sorry, I didn't understand that."

async def send_welcome_message(chat_id):
    welcome_text = (
        "ðŸŒŸ Salam! Welcome to the Egyptian Arabic Adventure Bot! ðŸŒŸ\n\n"
        "Embark on an exciting journey to master the beautiful Egyptian Arabic language. ðŸ—ºï¸âœ¨\n\n"
        "To start your adventure, simply click on /start and let the magic unfold! âœ¨ðŸ“š\n\n"
        "Ready to dive into the wonders of Egyptian Arabic? Let's get started!"
    )
    try:
        await bot.send_message(chat_id=chat_id, text=welcome_text)
        logging.info(f"Message sent to chat_id: {chat_id}")
    except Exception as e:
        logging.error(f"Failed to send message to chat_id: {chat_id}, error: {e}")

@dp.message(Command("start"))
async def start(message: types.Message):
    user_id = message.chat.id
    active_users.add(user_id)
    welcome_text = (
        "Yalla!\n"
        "/start - See available commands\n"
        "/model - Get information about the model\n"
        "/exercise - Get an exercise prompt\n"
        "/clear - Clear the conversation history"
    )
    await message.reply(welcome_text)
    await send_welcome_message(chat_id=user_id)

@dp.message(Command("clear"))
async def clear_history(message: types.Message):
    user_id = message.chat.id
    conversations[user_id] = {'conversations': [], 'responses': []}
    await message.reply("Conversations and responses cleared!")

@dp.message(Command("model"))
async def handle_model_command(message: Message):
    user_id = message.chat.id
    user_states[user_id] = 'model'
    await message.reply("You are now chatting with the model. Type your messages to start.")

@dp.message(Command("exercise"))
async def handle_exercise_command(message: Message):
    await message.reply("This feature is in progress, stay tuned!")

@dp.message()
async def handle_message(message: types.Message):
    user_id = message.chat.id
    logging.debug(f"Received message from user_id {user_id}: {message.text}")

    if user_states.get(user_id) == 'model':
        response = await generate_response_with_model_and_faiss(
            message_list=[{"role": "user", "content": message.text}],
            model=model,
            tokenizer=tokenizer,
            device=device
        )
        await message.reply(response[0])
    else:
        response = "This is a placeholder response."
        await message.reply(response)

import random

def generate_random_exercise(sentences):
    """
    Generates a random exercise from the list of sentences.

    Args:
        sentences (list): List of sentences to choose from.

    Returns:
        tuple: Contains the exercise sentence with a blank, the correct word, and the list of options.
    """
    if not sentences:
        return None, None, None

    sentence = random.choice(sentences)
    words = sentence.split()

    if len(words) < 2:
        return None, None, None

    blank_index = random.randint(0, len(words) - 1)
    correct_word = words[blank_index]
    words[blank_index] = '____'

    options = [correct_word]
    all_words = ' '.join(sentences).split()
    while len(options) < 4:
        word = random.choice(all_words)
        if word not in options:
            options.append(word)

    random.shuffle(options)
    exercise = ' '.join(words)

    return exercise, correct_word, options

sentences = cleaned_df['text'].tolist()
exercise_text, correct_word, options = generate_random_exercise(sentences)

print("Exercise Sentence: ", exercise_text)
print("Correct Word: ", correct_word)
print("Options: ", options)

# Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ ÑƒÐ¿Ñ€Ð°Ð¶Ð½ÐµÐ½Ð¸Ð¹, Ð² Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐµ Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ¸
#@bot.message_handler(commands=['exercise'])
#def handle_exercise_command(message):
#    user_id = message.chat.id

#    user_states[user_id] = 'exercise'

    #task = generate_exercise_task.delay()

#    def send_exercise():
#        while not task.ready():
#            asyncio.sleep(1)

#        exercise_text, correct_word, options = task.result

#        if exercise_text is None:
#            bot.send_message(user_id, "No exercise could be generated.")
#            return

 #       options_text = '\n'.join(f"{i+1}. {opt}" for i, opt in enumerate(options))

  #      message_text = f"Complete the sentence:\n{exercise_text}\n\nOptions:\n{options_text}"
  #      bot.send_message(user_id, message_text)

   # import threading
   # threading.Thread(target=send_exercise).start()

import asyncio
!pip install --upgrade aiogram

import nest_asyncio
nest_asyncio.apply()

async def main():
    logging.info("Starting bot...")
    await dp.start_polling(bot)

if __name__ == "__main__":
    logging.info("Bot is starting...")
    asyncio.run(main())